\documentclass{extarticle}
\sloppy

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PACKAGES            																						  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[10pt]{extsizes}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage[shortlabels]{enumitem}
\usepackage{microtype} 
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{commath}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PROBLEM ENVIRONMENT         																			           %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tcolorbox}
\tcbuselibrary{theorems, breakable, skins}
\newtcbtheorem{prob}% environment name
              {Problem}% Title text
  {enhanced, % tcolorbox styles
  attach boxed title to top left={xshift = 4mm, yshift=-2mm},
  colback=blue!5, colframe=black, colbacktitle=blue!3, coltitle=black,
  boxed title style={size=small,colframe=gray},
  fonttitle=\bfseries,
  separator sign none
  }%
  {} 
\newenvironment{problem}[1]{\begin{prob*}{#1}{}}{\end{prob*}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS/LEMMAS/ETC.         																			  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newtheorem{thm}{Theorem}
\newtheorem*{thm-non}{Theorem}
\newtheorem{lemma}[thm]{Lemma}
\newtheorem{corollary}[thm]{Corollary}
\newtheorem*{definition}{Definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MY COMMANDS   																						  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\bigO}{\mathcal{O}}
\newcommand{\Real}{\mathcal{Re}}
\newcommand{\poly}{\mathcal{P}}
\newcommand{\mat}{\mathcal{M}}
\DeclareMathOperator{\Span}{span}
\newcommand{\Hom}{\mathcal{L}}
\DeclareMathOperator{\Null}{null}
\DeclareMathOperator{\Range}{range}
\newcommand{\defeq}{\vcentcolon=}
\newcommand\widebar[1]{\mathop{\overline{#1}}}
\newcommand{\restr}[1]{|_{#1}}
\DeclarePairedDelimiterX{\inp}[2]{\langle}{\rangle}{#1, #2}
\DeclarePairedDelimiter\Mod{\lvert}{\rvert}
\DeclarePairedDelimiter\Norm{\lVert}{\rVert}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION NUMBERING																				           %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\renewcommand\thesection{\Alph{section}:}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% DOCUMENT START              																			           %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\vspace{-2em}Chapter 6: Inner Product Spaces}
\author{\emph{Linear Algebra Done Right}, by Sheldon Axler}
\date{}

\begin{document}
\maketitle



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SECTION A            																			           
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Inner Products and Norms}

% Problem 1
\begin{problem}{1}
Show that the function that takes $\left((x_1,x_2), (y_1,y_2)\right)\in \R^2\times \R^2$ to $\Mod{x_1y_1} + \Mod{x_2y_2}$ is not an inner product on $\R^2$.
\end{problem}
\begin{proof}
Suppose it were.  First notice
\begin{align*}
\inp{(1, 1) + (-1, -1)}{(1, 1)} &= \inp{(0, 0)}{(1, 1)}\\
&= \Mod{0\cdot 1} + \Mod{0\cdot 1}\\
&= 0.
\end{align*}
Next, since inner products are additive in the first slot, we also have
\begin{align*}
\inp{(1, 1) + (-1, -1)}{(1, 1)} &= \inp{(1, 1)}{(1, 1)} + \inp{(-1, -1)}{(1, 1)}\\
&= \Mod{1\cdot 1} + \Mod{1 \cdot 1} + \Mod{(-1)\cdot 1} + \Mod{(-1) \cdot 1}\\
&= 4.
\end{align*}
But this implies $0 = 4$, a contradiction.  Hence we must conclude that the function does not in fact define an inner product.
\end{proof}

% Problem 3
\begin{problem}{3}
Suppose $\F=\R$ and $V\neq \{0\}$.  Replace the positivity condition (which states that $\inp{v}{v}\geq0$ for all $v\in V$) in the definition of an inner product (6.3) with the condition that $\inp{v}{v} > 0$ for some $v\in V$.  Show that this change in the definition does not change the set of functions from $V\times V$ to $\R$ that are inner products on $V$.
\end{problem}
\begin{proof}
Let $V$ be a nontrivial vector space over $\R$, let $A$ denote the set of functions $V\times V\to\R$ that are inner products on $V$ in the standard definition, and let $B$ denote the set of functions $V\times V\to \R$ under the modified definition.  We will show $A = B$.\\
\indent Suppose $\inp{\cdot}{\cdot}_1\in A$.  Since $V\neq\{0\}$, there exists $v\in V-\{0\}$.  Then $\inp{v}{v}_1>0$, and so $\inp{\cdot}{\cdot}_1\in B$.  Thus $A\subseteq B$.\\ 
\indent Conversely, suppose $\inp{\cdot}{\cdot}_2 \in B$.  Then there exists some $v'\in V$ such that $\inp{v'}{v'}_2 > 0$.  Suppose by way of contradiction there exists $u\in V$ is such that $\inp{u}{u}_2 < 0$.  Define $w = \alpha u + (1- \alpha) v'$ for $\alpha\in\R$.  It follows
\begin{align*}
\inp{w}{w}_2 &= \inp{\alpha u + (1- \alpha) v'}{\alpha u + (1- \alpha) v'}_2\\
&= \inp{\alpha u}{\alpha u}_2 + 2\inp{\alpha u}{(1 - \alpha)v'}_2 + \inp{(1 - \alpha)v'}{(1 - \alpha)v'}_2\\
&= \alpha^2\inp{u}{u}_2 + 2\alpha(1-\alpha)\inp{u}{v'}_2 + (1-\alpha)^2\inp{v'}{v'}_2.
\end{align*}
Notice the final expression is a polynomial in the indeterminate $\alpha$, call it $p$.  Since $p(0) = \inp{v'}{v'}_2 > 0$ and $p(1) = \inp{u}{u}_2 < 0$, by Bolzano's theorem there exists $\alpha_0\in(0, 1)$ such that $p(\alpha_0) = 0$.  That is, if $ w = \alpha_0u + (1 - \alpha_0)v'$, then $\inp{w}{w}_2 = 0$.  In particular, notice $\alpha_0\neq 0$, for otherwise $w = v'$, a contradiction since $\inp{v'}{v'}_2 > 0$.  Now, since $\inp{w}{w}_2 = 0$ iff $w = 0$ (by the definiteness condition of an inner product), it follows 
\begin{equation*}
u = \frac{\alpha_0 - 1}{\alpha_0} v.
\end{equation*}
Letting $t =  \frac{\alpha_0 - 1}{\alpha_0}$, we now have
\begin{align*}
\inp{u}{u}_2 &= \inp{tv'}{tv'}_2\\
&= t^2\inp{v'}{v'}_2\\
&> 0,
\end{align*}
where the inequality follows since $t\in(-1, 0)$ and $\inp{v'}{v'}_2 > 0$.  This contradicts our assumption that $\inp{u}{u}_2 < 0$, and so we have $\inp{\cdot}{\cdot}_2\in A$.  Therefore, $B\subseteq A$.  Since we've already shown $A\subseteq B$, this implies $A = B$, as desired.
\end{proof}

% Problem 5
\begin{problem}{5}
Let $V$ be finite-dimensional.  Suppose $T\in\Hom(V)$ is such that $\Norm{Tv}\leq \Norm{v}$ for every $v\in V$.  Prove that $T-\sqrt{2}I$ is invertible.
\end{problem}
\begin{proof}
Let $v\in\Null(T - \sqrt{2}I)$, and suppose by way of contradiction that $v\neq 0$.  Then
\begin{align*}
Tv - \sqrt{2}v = 0 &\implies Tv = \sqrt{2}v\\
&\implies \Norm{\sqrt{2}v}\leq \Norm{v}\\
&\implies \sqrt{2}\cdot \Norm{v}\leq \Norm{v}\\
&\implies \sqrt{2} \leq 1,
\end{align*}
a contradiction.  Hence $v = 0$ and $\Null(T - \sqrt{2}I) =\{0\}$, so that $T-\sqrt{2}I$ is injective.  Since $V$ is finite-dimensional, this implies $T-\sqrt{2}I$ is invertible, as desired.
\end{proof}

% Problem 7
\begin{problem}{7}
Suppose $u,v\in V$.  Prove that $\Norm{au + bv} = \Norm{bu + av}$ for all $a,b\in\R$ if and only if $\Norm{u} = \Norm{v}$.
\end{problem}
\begin{proof}
$(\Rightarrow)$ Suppose $\Norm{au + bv} = \Norm{bu + av}$ for all $a,b\in\R$.  Then this equation holds when $a = 1$ and $b = 0$.  But then we must have $\Norm{u} = \Norm{v}$, as desired.\\
\indent $(\Leftarrow)$ Conversely, suppose $\Norm{u} = \Norm{v}$.  Let $a,b\in\R$ be arbitrary, and notice
\begin{align}
\Norm{au + bv} &= \inp{au + bv}{au + bv} \nonumber \\
&= \inp{au}{au} + \inp{au}{bv} + \inp{bv}{au} + \inp{bv}{bv} \nonumber \\
&= a^2\Norm{u}^2 + ab\left(\inp{u}{v} + \inp{v}{u}\right) + b^2\Norm{v}^2. \label{eq1}
\end{align}
Also, we have
\begin{align}
\Norm{bu + av} &= \inp{bu + av}{bu + av} \nonumber \\
&= \inp{bu}{bu} + \inp{bu}{av} + \inp{av}{bu} + \inp{av}{av} \nonumber \\
&= b^2\Norm{u}^2 + ab\left(\inp{u}{v} + \inp{v}{u}\right) + a^2\Norm{v}^2. \label{eq2}
\end{align}
Since $\Norm{u} = \Norm{v}$, \eqref{eq1} equals \eqref{eq2}, and hence $\Norm{au + bv} = \Norm{bu + av}$.  Since $a,b$ were arbitrary, the result follows.
\end{proof}

% Problem 9
\begin{problem}{9}
Suppose $u,v\in V$ and $\Norm{u}\leq 1$ and $\Norm{v}\leq 1$.  Prove that 
\begin{equation*}
\sqrt{1 - \Norm{u}^2}\sqrt{1 - \Norm{v}^2}\leq 1 - \Mod{\inp{u}{v}}.
\end{equation*}
\end{problem}
\begin{proof}
By the Cauchy-Schwarz Inequality, we have $\Mod{\inp{u}{v}}\leq \Norm{u}\Norm{v}$.  Since $\Norm{u}\leq 1$ and $\Norm{v}\leq 1$, this implies
\begin{align*}
0 \leq 1 -\Norm{u}\Norm{v} \leq 1 -\Mod{\inp{u}{v}},
\end{align*}
and hence it's enough to show
\begin{equation*}
\sqrt{1 - \Norm{u}^2}\sqrt{1 - \Norm{v}^2} \leq 1 -\Norm{u}\Norm{v}.
\end{equation*}
Squaring both sides, it suffices to prove 
\begin{equation}
\left(1 - \Norm{u}^2\right)\left(1 - \Norm{v}^2\right) \leq \left(1 -\Norm{u}\Norm{v}\right)^2. \label{eq3}
\end{equation}
Notice
\begin{align*}
\left(1 -\Norm{u}\Norm{v}\right)^2 - \left(1 - \Norm{u}^2\right)\left(1 - \Norm{v}^2\right) &= \Norm{u}^2 - 2\Norm{u}\Norm{v} + \Norm{v}^2\\
&= \left(\Norm{u} - \Norm{v}\right)^2\\
&\geq 0,
\end{align*}
and hence inequality \eqref{eq3} holds, completing the proof.
\end{proof}

% Problem 11
\begin{problem}{11}
Prove that
\begin{equation*}
16 \leq (a + b + c + d)\left(\frac{1}{a} + \frac{1}{b} + \frac{1}{c} + \frac{1}{d}\right)
\end{equation*}
for all positive numbers $a,b,c,d$.
\end{problem}
\begin{proof}
Define
\begin{align*}
x = \left(\sqrt{a}, \sqrt{b}, \sqrt{c}, \sqrt{d} \right)\quad\text{and}\quad y = \left(\sqrt{\frac{1}{a}}, \sqrt{\frac{1}{b}}, \sqrt{\frac{1}{c}}, \sqrt{\frac{1}{d}}\right).
\end{align*}
Then the Cauchy-Schwarz Inequality implies
\begin{align*}
(a + b + c + d)\left(\frac{1}{a} + \frac{1}{b} + \frac{1}{c} + \frac{1}{d}\right) &\geq \left(\sqrt{a}\sqrt{\frac{1}{a}} + \sqrt{b}\sqrt{\frac{1}{b}} + \sqrt{c}\sqrt{\frac{1}{c}} + \sqrt{d}\sqrt{\frac{1}{d}}\right)^2\\
&= (1 + 1 + 1 + 1)^2\\
&= 16,
\end{align*}
as desired.
\end{proof}

% Problem 13
\begin{problem}{13}
Suppose $u,v$ are nonzero vectors in $\R^2$.  Prove that
\begin{equation*}
\inp{u}{v} = \Norm{u}\Norm{v}\cos\theta,
\end{equation*}
where $\theta$ is the angle between $u$ and $v$ (thinking of $u$ and $v$ as arrows with initial point at the origin).
\end{problem}
\begin{proof}
Let $A$ denote the line segment from the origin to $u$, let $B$ denote the line segment from the origin to $v$, and let $C$ denote the line segment from $v$ to $u$.  Then $A$ has length $\Norm{u}$, $B$ has length $\Norm{v}$ and $C$ has length $\Norm{u - v}$.  Letting $\theta$ denote the angle between $A$ and $B$, by the Law of Cosines we have
\begin{align*}
C^2 = A^2 + B^2 - 2BC\cos\theta,
\end{align*} 
or equivalently
\begin{align*}
\Norm{u - v}^2 = \Norm{u}^2 + \Norm{v}^2 - 2\Norm{u}\Norm{v}\cos\theta.
\end{align*}
It follows
\begin{align*}
2\Norm{u}\Norm{v}\cos\theta &= \Norm{u}^2 + \Norm{v}^2 - \Norm{u-v}^2\\
&= \inp{u}{u} + \inp{v}{v} - \inp{u-v}{u-v}\\
&= \inp{u}{u} + \inp{v}{v} - \left(\inp{u}{u} - 2\inp{u}{v} + \inp{v}{v}\right)\\
&= 2\inp{u}{v}.
\end{align*}
Dividing both sides by $2$ gives the desired result.
\end{proof}

% Problem 15
\begin{problem}{15}
Prove that 
\begin{equation*}
\left(\sum_{j = 1}^na_j b_j\right)^2 \leq \left(\sum_{j = 1}^nj{a_j}^2\right)\left(\sum_{j=1}^n\frac{{b_j}^2}{j}\right)
\end{equation*}
for all real numbers $a_1,\dots,a_n$ and $b_1,\dots,b_n$.
\end{problem}
\begin{proof}
Let
\begin{equation*}
u = \left(a_1, \sqrt{2}a_2, \dots, \sqrt{n}a_n\right)\quad\text{and}\quad v =\left(b_1, \frac{1}{\sqrt{2}}b_2,\dots, \frac{1}{\sqrt{n}}b_n\right).
\end{equation*}
Since $\inp{u}{v} = \sum_{k=1}^na_kb_k$, the Cauchy-Schwarz Inequality yields
\begin{align*}
\left(a_1b_1 +\dots + a_nb_n\right)^2 &\leq \Norm{u}^2\Norm{v}^2\\
&=\left({a_1}^2 + 2{a_2}^2 + \dots + n{a_n}^2\right)\left({b_1}^2 + \frac{{b_2}^2}{2} + \dots + \frac{{b_n}^2}{n}\right),
\end{align*}
as desired.
\end{proof}

% Problem 17
\begin{problem}{17}
Prove or disprove: there is an inner product on $\R^2$ such that the associated norm is given by 
\begin{equation*}
\Norm{(x,y)} = \max\{\Mod{x},\Mod{y}\}
\end{equation*}
for all $(x, y)\in\R^2$.
\end{problem}
\begin{proof}
Suppose such an inner product existed.  Then by the Parallelogram Equality, it follows
\begin{align*}
\Norm{(1, 0) + (0, 1)}^2 + \Norm{(1, 0) - (0, 1)}^2 = 2\left(\Norm{(1,0)}^2 + \Norm{(0,1)}^2\right).
\end{align*}
After simplification, this implies $2 = 4$, a contradiction.  Hence no such inner product exists.
\end{proof}

% Problem 19
\begin{problem}{19}
Suppose $V$ is a real inner product space.  Prove that
\begin{equation*}
\inp{u}{v} = \frac{\Norm{u+v}^2 - \Norm{u - v}^2}{4}
\end{equation*}
for all $u,v\in V$.
\end{problem}
\begin{proof}
Suppose $V$ is a real inner product space and let $u,v\in V$.  It follows
\begin{align*}
\frac{\Norm{u+v}^2 - \Norm{u - v}^2}{4} &= \frac{\left(\Norm{u}^2 + 2\inp{u}{v} +\Norm{v}^2\right) - \left(\Norm{u}^2 - 2\inp{u}{v} +\Norm{v}^2\right)}{4}\\
&= \frac{4\inp{u}{v}}{4}\\
&= \inp{u}{v},
\end{align*}
as desired.
\end{proof}

% Problem 20
\begin{problem}{20}
Suppose $V$ is a complex inner product space.  Prove that
\begin{equation*}
\inp{u}{v} = \frac{\Norm{u+v}^2 - \Norm{u - v}^2 + \Norm{u + iv}^2i - \Norm{u -iv}^2i}{4}
\end{equation*}
for all $u,v\in V$.
\end{problem}
\begin{proof}
Notice we have
\begin{align*}
\Norm{u + v}^2 &= \inp{u + v}{u + v}\\
&=\Norm{u}^2 +\inp{u}{v} + \inp{v}{u} + \Norm{v}^2
\end{align*}
and
\begin{align*}
-\Norm{u - v}^2 &= -\inp{u - v}{u - v}\\
&=-\Norm{u}^2 + \inp{u}{v} + \inp{v}{u} - \Norm{v}^2.
\end{align*}
Also, we have
\begin{align*}
\Norm{u + iv}^2i &= i\left(\inp{u + iv}{u+iv}\right)\\
&= i\left(\Norm{u}^2 + \inp{u}{iv} + \inp{iv}{u} + \inp{iv}{iv}\right)\\
&= i\left(\Norm{u}^2 - i\inp{u}{v} + i\inp{v}{u} + \Norm{v}^2\right)\\
&= i\Norm{u}^2 + \inp{u}{v} - \inp{v}{u} + i\Norm{v}^2
\end{align*}
and
\begin{align*}
-\Norm{u - iv}^2i &= -i\left(\inp{u - iv}{u-iv}\right)\\
&= -i\left(\Norm{u}^2 - \inp{u}{iv} - \inp{iv}{u} + \inp{iv}{iv}\right)\\
&= -i\left(\Norm{u}^2 + i\inp{u}{v} - i\inp{v}{u} + \Norm{v}^2\right)\\
&= -i\Norm{u}^2 + \inp{u}{v} - \inp{v}{u} - i\Norm{v}^2.
\end{align*}
Thus it follows
\begin{align*}
\Norm{u+v}^2 - \Norm{u - v}^2 + \Norm{u + iv}^2i - \Norm{u -iv}^2i = 4\inp{u}{v}.
\end{align*}
Dividing both sides by $4$ yields the desired result.
\end{proof}

%% Problem 21
%\begin{problem}{21}
%A norm on a vector space $U$ is a function $\Norm{\cdot}: U\to [0,\infty)$ such that $\Norm{u} = 0$ if and only if $u=0$, $\Norm{\alpha u} = \Mod{\alpha}\Norm{u}$ for all $\alpha\in\F$ and all $u\in U$, and $\Norm{u + v}\leq\Norm{u} + \Norm{v}$ for all $u,v\in U$.  Prove that a norm satisfying the parallelogram equality comes from an inner product (in other words, show that if $\Norm{\cdot}$ is a norm on $U$ satisfying the parallelogram equality, then there is an inner product $\inp{\cdot}{\cdot}$ on $U$ such that $\Norm{u} = \inp{u}{u}^{1/2}$ for all $u\in U$).
%\end{problem}
%\begin{proof}
%\begin{equation*}
%60 * 0.15 = 0.10 * 60 + 0.05 * 60 = 6 + 3 = 9
%\end{equation*}
%\end{proof}

% Problem 23
\begin{problem}{23}
Suppose $V_1, \dots, V_m$ are inner product spaces.  Show that the equation
\begin{equation*}
\inp{(u_1,\dots, u_m)}{(v_1,\dots, v_m)} = \inp{u_1}{v_1} + \dots + \inp{u_m}{v_m}
\end{equation*}
defines an inner product on $V_1\times \dots \times V_m$. 
\end{problem}
\begin{proof}
We prove that this definition satisfies each property of an inner product in turn.\\
\textbf{Positivity: } Let $(v_1,\dots, v_m)\in V_1\times\dots V_m$.  Since $\inp{v_k}{v_k}$ is an inner product on $V_k$ for $k = 1,\dots, m$, we have $\inp{v_k}{v_k}\geq 0$.  Thus
\begin{equation*}
\inp{(v_1,\dots, v_m)}{(v_1,\dots, v_m)} = \inp{v_1}{v_1} + \dots + \inp{v_m}{v_m} \geq 0.
\end{equation*}
\textbf{Definiteness: } First suppose $\inp{(v_1,\dots, v_m)}{(v_1,\dots, v_m)} = 0$ for $(v_1,\dots, v_m)\in V_1\times\dots\times V_m$.  Then
\begin{equation*}
\inp{v_1}{v_1} + \dots + \inp{v_m}{v_m} = 0.
\end{equation*}
By positivity of each inner product on $V_k$ (for $k = 1,\dots, m$), we must have $\inp{v_k}{v_k}\geq 0$.  Thus the equation above holds only if $\inp{v_k}{v_k} = 0$ for each $k$, which is true iff $v_k = 0$ (by definiteness of the inner product on $V_k$).  Hence $(v_1, \dots, v_m) = (0, \dots, 0)$.  Conversely, suppose $(v_1,\dots, v_m) = (0, \dots, 0)$.  Then 
\begin{align*}
\inp{(v_1,\dots, v_m)}{(v_1,\dots, v_m)} &= \inp{v_1}{v_1} + \dots + \inp{v_m}{v_m}\\
&= \inp{0}{0} + \dots + \inp{0}{0}\\
&= 0 + \dots + 0\\
&= 0,
\end{align*}
where the third equality follows from definiteness of the inner product on each $V_k$, respectively.\\
\textbf{Additivity in first slot: } Let 
\begin{equation*}
(u_1,\dots, u_m), (v_1,\dots, v_m), (w_1,\dots, w_m)\in V_1\times\dots\times V_m.
\end{equation*}  
It follows
\begin{align*}
\langle (u_1, \dots, u_m) + &(v_1,\dots, v_m)), (w_1,\dots, w_m)\rangle \\
&= \inp{(u_1 + v_1, \dots, u_m + v_m)}{(w_1,\dots, w_m)}\\
&= \inp{u_1 + v_1}{w_1} + \dots + \inp{u_m + v_m}{w_m}\\
&= \inp{u_1}{w_1} + \inp{v_1}{w_1} + \dots + \inp{u_m}{w_m} + \inp{v_m}{w_m}\\
&= \inp{(u_1,\dots,u_m)}{(w_1,\dots, w_m)} + \inp{(v_1,\dots, v_m)}{(w_1,\dots,w_m)},
\end{align*}
where the third equality follows from additivity in the first slot of each inner product on $V_k$, respectively.\\
\textbf{Homogeneity in the first slot: } Let $\lambda\in\F$ and 
\begin{equation*}
(u_1,\dots, u_m),(v_1,\dots, v_m)\in V_1\times \dots \times V_m.
\end{equation*}
It follows
\begin{align*}
\inp{\lambda(u_1,\dots, u_m)}{(v_1,\dots, v_m)} &= \inp{(\lambda u_1,\dots, \lambda u_m)}{(v_1,\dots, v_m)} \\
&= \inp{\lambda u_1}{v_1} + \dots + \inp{\lambda u_m}{v_m}\\
&= \lambda\inp{u_1}{v_1} + \dots + \lambda\inp{u_m}{v_m}\\
&= \lambda(\inp{u_1}{v_1} + \dots + \inp{u_m}{v_m})\\
&=\lambda\inp{(u_1,\dots, u_m)}{(v_1,\dots, v_m)},
\end{align*}
where the third equality follows from homogeneity in the first slot of each inner product on $V_k$, respectively.\\
\textbf{Conjugate symmetry: } Again let
\begin{equation*}
(u_1,\dots, u_m),(v_1,\dots, v_m)\in V_1\times \dots \times V_m.
\end{equation*}
It follows
\begin{align*}
\inp{(u_1,\dots, u_m)}{(v_1,\dots, v_m)} &=  \inp{u_1}{v_1} + \dots + \inp{u_m}{v_m}\\
&= \widebar{\inp{v_1}{u_1}} + \dots + \widebar{\inp{v_m}{u_m}}\\
&= \widebar{\inp{u_1}{v_1} + \dots + \inp{u_m}{v_m}}\\
&= \widebar{\inp{(v_1,\dots, v_m)}{(u_1,\dots, u_m)}},
\end{align*}
where the second equality follows from conjugate symmetry of each inner product on $V_k$, respectively.
\end{proof}

% Problem 24
\begin{problem}{24}
Suppose $S\in\Hom(V)$ is an injective operator on $V$.  Define $\inp{\cdot}{\cdot}_1$ by
\begin{equation*}
\inp{u}{v}_1 = \inp{Su}{Sv}
\end{equation*}
for $u,v\in V$.  Show that $\inp{\cdot}{\cdot}_1$ is an inner product on $V$.
\end{problem}
\begin{proof}
We prove that this definition satisfies each property of an inner product in turn.\\
\textbf{Positivity: } Let $v\in V$.  Then $\inp{v}{v}_1 = \inp{Sv}{Sv} \geq 0$.\\
\textbf{Definiteness: } Suppose $\inp{v}{v} = 0$ for some $v\in V$.  This is true iff $\inp{Sv}{Sv} = 0$ (by definition) which is true iff $Sv = 0$ (by definiteness of $\inp{\cdot}{\cdot}$), which is true iff $v = 0$ (since $S$ is injective).\\
\textbf{Additivity in first slot: } Let $u, v, w\in V$.  Then
\begin{align*}
\inp{u + v}{w}_1 &= \inp{S(u + v)}{Sw}\\
&= \inp{Su + Sv}{Sw}\\
&= \inp{Su}{Sw} + \inp{Sv}{Sw}\\
&= \inp{u}{w}_1 + \inp{v}{w}_1.
\end{align*}
\textbf{Homogeneity in first slot: } Let $\lambda\in\F$ and $u, v\in V$.  Then
\begin{align*}
\inp{\lambda u}{v}_1 &= \inp{S(\lambda u)}{Sv}\\
&= \inp{\lambda Su}{Sv}\\
&= \lambda \inp{Su}{Sv}\\
&= \lambda\inp{u}{v}_1.
\end{align*}
\textbf{Conjugate symmetry} Let $u,v\in V$.  Then
\begin{align*}
\inp{u}{v}_1 &= \inp{Su}{Sv}\\
&= \widebar{\inp{Sv}{Su}}\\
&= \widebar{\inp{v}{u}_1}.
\end{align*}
\end{proof}

% Problem 25
\begin{problem}{25}
Suppose $S\in\Hom(V)$ is not injective.  Define $\inp{\cdot}{\cdot}_1$ as in the exercise above.  Explain why $\inp{\cdot}{\cdot}_1$ is not an inner product on $V$.
\end{problem}
\begin{proof}
If $S$ is not injective, then $\inp{\cdot}{\cdot}_1$ fails the definiteness requirement in the definition of an inner product.  In particular, there exists $v\neq 0$ such that $Sv =0$.  Hence $\inp{v}{v}_1 = \inp{Sv}{Sv} = 0$ for a nonzero $v$.
\end{proof}

% Problem 27
\begin{problem}{27}
Suppose $u,v,w\in V$.  Prove that
\begin{equation*}
\norm{w - \frac{1}{2}(u + v)}^2 = \frac{\norm{w - u}^2 + \norm{w - v}^2}{2} - \frac{\norm{u - v}^2}{4}.
\end{equation*}
\end{problem}
\begin{proof}
We have
\begin{align*}
\norm{w - \frac{1}{2}(u + v)}^2 &= \norm{\left(\frac{w - u}{2}\right) + \left(\frac{w - v}{2} \right)}^2\\
&=  2\norm{\frac{w - u}{2}}^2 + 2 \norm{\frac{w - v}{2}}^2 - \norm{\left(\frac{w-u}{2}\right) - \left(\frac{w-v}{2}\right)}^2\\
&= \frac{\norm{w-u}^2 + \norm{w - v}}{2} - \norm{\frac{-u + v}{2}}\\
&= \frac{\norm{w-u}^2 + \norm{w - v}}{2} - \frac{\norm{u - v}^2}{4},
\end{align*}
where the second equality follows by the Parallelogram Equality.
\end{proof}

The next problem requires some extra work to prove.  We first include a definition and prove a theorem.
\begin{definition}
Suppose $\norm{\cdot}_1$ and $\norm{\cdot}_2$ are norms on vector space $V$.  We say $\norm{\cdot}_1$ and $\norm{\cdot}_2$ are \emph{equivalent} if there exist $0 < C_1\leq C_2$ such that 
\begin{equation*}
C_1 \norm{v}_1 \leq \norm{v}_2 \leq C_2 \norm{v}_1
\end{equation*}
for all $v\in V$.
\end{definition}
\begin{thm-non}
Any two norms on a finite-dimensional vector space are equivalent.
\end{thm-non}
\begin{proof}
Let $V$ be finite-dimensional with basis $e_1,\dots, e_n$.  If suffices to prove that every norm on $V$ is equivalent to the $\ell_1$-style norm $\norm{\cdot}_1$ defined by
\begin{equation*}
\norm{v}_1 = \abs{\alpha_1} + \dots + \abs{\alpha_n}
\end{equation*}
for all $v = \alpha_1e_1 + \dots + \alpha_ne_n\in V$.\\
\indent Let $\norm{\cdot}$ be a norm on $V$.  We wish to show $C_1\norm{v}_1 \leq \norm{v}\leq C_2\norm{v}_1$ for all $v\in V$ and some choice of $C_1,C_2$.  Since this is trivially true for $v = 0$, we need only consider $v\neq 0$, in which case we have
\begin{align*}
C_1 \leq \norm{u} \leq C_2, \tag{*}\label{key}
\end{align*}
where $u = v/\norm{v}_1$.  Thus it suffices to consider only vectors $v\in V$ such that $\norm{v}_1 = 1$.\\
\indent We will now show that $\norm{\cdot}$ is continuous under $\norm{\cdot}_1$ and apply the extreme value theorem to deduce the desired result.  So let $\epsilon > 0$ and define $M = \max\{\norm{e_1}, \dots, \norm{e_n}\}$ and
\begin{equation*}
\delta = \frac{\epsilon}{M}.
\end{equation*}
It follows that if $u,v\in V$ are such that $\norm{u - v}_1 < \delta$, then
\begin{align*}
\abs{\norm{u} - \norm{v}} &\leq \norm{u - v}\\
&\leq M\norm{u - v}_1\\
&\leq M\delta \\
&= \epsilon,
\end{align*}
and $\norm{\cdot}$ is indeed continuous under the topology induced by $\norm{\cdot}_1$.  Let $\mathcal{S} = \{u\in V\mid \norm{u}_1=1\}$ (the unit sphere with respect to $\norm{\cdot}_1$).  Since $\mathcal{S}$ is compact and $\norm{\cdot}$ is continuous on it, by the extreme value theorem we may define
\begin{align*}
C_1 = \min_{u \in \mathcal{S}}\norm{u}~~~\text{and}~~~C_2 =  \max_{u \in \mathcal{S}}\norm{u}.
\end{align*}
But now $C_1$ and $C_2$ satisfy \eqref{key}, completing the proof.
\end{proof}

% Problem 29
\begin{problem}{29}
For $u,v \in V$, define $d(u,v) = \norm{u - v}$.  
\begin{enumerate}[(a)]
\item Show that $d$ is a metric on $V$.
\item Show that if $V$ is finite-dimensional, then $d$ is a complete metric on $V$ (meaning that every Cauchy sequence converges).
\item Show that every finite-dimensional subspace of $V$ is a closed subset of $V$ (with respect to the metric $d$).
\end{enumerate}
\end{problem}
\begin{proof}
\begin{enumerate}[(a)]
\item We show that $d$ satisfies each property of the definition of a metric in turn.\\
\textbf{Identity of indiscernibles: } Let $u, v\in V$.  It follows
\begin{align*}
d(u, v) = 0 &\iff \sqrt{\inp{u-v}{u-v}} = 0\\
&\iff \inp{u - v, u- v} = 0\\
&\iff u - v = 0\\
&\iff u = v.
\end{align*}
\textbf{Symmetry: } Let $u, v\in V$.  We have
\begin{align*}
d(u, v) &= \norm{u - v}\\
&= \norm{(-1)(u - v)}\\
&= \norm{v - u}\\
&= d(v, u).
\end{align*}
\textbf{Triangle inequality: } Let $u, v, w\in V$.  Notice
\begin{align*}
d(u,v) + d(v, w) &= \norm{u - v} + \norm{v - w}\\
&\leq \norm{(u - v) + (v - w)}\\
&= \norm{u, w}\\
&= d(u,w).
\end{align*}
\item Suppose $V$ is a $p$-dimensional vector space with basis $e_1,\dots, e_p$.  Assume $\{v_k\}_{k = 1}^\infty$ is Cauchy.  Then for $\epsilon > 0$, there exists $N\in\Z^+$ such that $\norm{v_m - v_n} < \epsilon$ whenever $m,n > N$.  Given any $v_i$ in our Cauchy sequence, we adopt the notation that $\alpha_{i, 1}, \dots, \alpha_{i, p}\in \F$ are always defined such that 
\begin{equation*}
v_i = \alpha_{i, 1}e_1 + \dots + \alpha_{i, p}e_p.
\end{equation*}
By our previous theorem, $\norm{\cdot}$ is equivalent to $\norm{\cdot}_1$ (where $\norm{\cdot}_1$ is defined in that theorem's proof).  Thus there exists some $c > 0$ such that, whenever $m,n > N$, we have
\begin{align*}
c\norm{v_m - v_n}_1 \leq \norm{v_m - v_n}  < \epsilon,
\end{align*}
and hence 
\begin{equation*}
c\left(\sum_{i = 1}^p\abs{\alpha_{m, i} - \alpha_{n, i}}\right) < \epsilon.
\end{equation*}
This implies that $\{\alpha_{k, i}\}_{k = 1}^\infty$ is Cauchy in $\R$ for each $i = 1,\dots, p$.  Since $\R$ is complete, these sequences converge.  So let $\alpha_i = \lim_{k \to \infty}\alpha_{k, i}$ for each $i$, and define $v = \alpha_1 e_1 + \dots + \alpha_p e_p$.  It follows
\begin{align*}
\norm{v_j - v} &= \norm{(\alpha_{j, 1} - \beta_1)e_1 + \dots + (\alpha_{j, p}-\beta_p)e_p}\\
&\leq \abs{\alpha_{j, 1}-\alpha_1}\norm{e_1} + \dots + \abs{\alpha_{j, p}-\alpha_p}\norm{e_p}.
\end{align*}
Since $\alpha_{j, i}\to \alpha_i$ for $i = 1,\dots, p$, the RHS can be made arbitrarily small by choosing sufficiently large $M\in\Z^+$ and considering $j > M$.  Thus $\{v_k\}_{k = 1}^\infty$ converges to $v$, and $V$ is indeed complete with respect to $\norm{\cdot}$.
\item Suppose $U$ is a finite-dimensional subspace of $V$, and suppose $\{u_k\}_{k=1}^\infty\subseteq U$ is Cauchy.  By (b), $\lim_{k \to \infty}u_k \in U$, hence $U$ contains all its limit points.  Thus $U$ is closed. \qedhere
\end{enumerate}

% Problem 31
\begin{problem}{31}
Use inner products to prove Apollonius's Identity: In a triangle with sides of length $a$, $b$, and $c$, let $d$ be the length of the line segment from the midpoint of the side of length $c$ to the opposite vertex.  Then
\begin{equation*}
a^2 + b^2 = \frac{1}{2}c^2 + 2d^2.
\end{equation*}
\end{problem}
\begin{proof}
Consider a triangle formed by vectors $v, w\in\R^2$ and the origin such that $\norm{w} = a$, $\norm{v} = c$, and $\norm{w - v} = b$.  The identity follows by applying Problem 27 with $u = 0$.
\end{proof}
\end{proof}


\end{document}